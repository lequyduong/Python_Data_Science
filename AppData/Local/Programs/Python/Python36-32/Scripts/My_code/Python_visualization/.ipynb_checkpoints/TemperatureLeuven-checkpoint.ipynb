{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Assignment 2\n",
    "\n",
    "Before working on this assignment please read these instructions fully. In the submission area, you will notice that you can click the link to Preview the Grading for each step of the assignment. This is the criteria that will be used for peer grading. Please familiarize yourself with the criteria before beginning the assignment.\n",
    "\n",
    "An NOAA dataset has been stored in the file data/C2A2_data/BinnedCsvs_d200/ecece9102a06a5925eab8542ca26a02ec74fca53f31672f58dd0aaad.csv. The data for this assignment comes from a subset of The National Centers for Environmental Information (NCEI) Daily Global Historical Climatology Network (GHCN-Daily). The GHCN-Daily is comprised of daily climate records from thousands of land surface stations across the globe.\n",
    "\n",
    "Each row in the assignment datafile corresponds to a single observation.\n",
    "\n",
    "The following variables are provided to you:\n",
    "\n",
    "    id : station identification code\n",
    "    date : date in YYYY-MM-DD format (e.g. 2012-01-24 = January 24, 2012)\n",
    "    element : indicator of element type\n",
    "        TMAX : Maximum temperature (tenths of degrees C)\n",
    "        TMIN : Minimum temperature (tenths of degrees C)\n",
    "    value : data value for element (tenths of degrees C)\n",
    "\n",
    "For this assignment, you must:\n",
    "\n",
    "    Read the documentation and familiarize yourself with the dataset, then write some python code which returns a line graph of the record high and record low temperatures by day of the year over the period 2005-2014. The area between the record high and record low temperatures for each day should be shaded.\n",
    "    Overlay a scatter of the 2015 data for any points (highs and lows) for which the ten year record (2005-2014) record high or record low was broken in 2015.\n",
    "    Watch out for leap days (i.e. February 29th), it is reasonable to remove these points from the dataset for the purpose of this visualization.\n",
    "    Make the visual nice! Leverage principles from the first module in this course when developing your solution. Consider issues such as legends, labels, and chart junk.\n",
    "\n",
    "The data you have been given is near Leuven, Flemish Brabant Province, Belgium, and the stations the data comes from are shown on the map below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data/C2A2_data/BinnedCsvs_d200/ecece9102a06a5925eab8542ca26a02ec74fca53f31672f58dd0aaad.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-972aa15880a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TMIN 2005-2014'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TMAX 2005-2014'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TMIN 2015'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TMAX 2015'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;31m#df_no_2015#observation_dates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m \u001b[0mplot_max_temp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-972aa15880a8>\u001b[0m in \u001b[0;36mplot_max_temp\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/C2A2_data/BinnedCsvs_d200/ecece9102a06a5925eab8542ca26a02ec74fca53f31672f58dd0aaad.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#df = df.remove\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\le quy duong\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\le quy duong\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\le quy duong\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\le quy duong\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\le quy duong\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'data/C2A2_data/BinnedCsvs_d200/ecece9102a06a5925eab8542ca26a02ec74fca53f31672f58dd0aaad.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mplleaflet\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "def plot_max_temp():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    df = pd.read_csv('data/C2A2_data/BinnedCsvs_d200/ecece9102a06a5925eab8542ca26a02ec74fca53f31672f58dd0aaad.csv')\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    #df = df.remove\n",
    "    #df['Date']=df['Date'].map(lambda x: x.replace(year=2015))\n",
    "    #df2015 = df[df['Date'].day = '29']\n",
    "    #df['Year'] = df['Date'].dt.year\n",
    "    #df['Month'] = df['Date'].dt.month\n",
    "    #df['Day'] = df['Date'].dt.day\n",
    "    df_yes_2015 = df[df['Date'].dt.year == 2015] # there is no 2015-29-02\n",
    "    #df_yes_2015 = (df_yes_2015.set_index('Date').groupby(level=0)['Data_Value']\n",
    "    #.agg({'TMAX': np.max, 'TMIN': np.min}))  \n",
    "    df_max_2015 = df_yes_2015[df_yes_2015['Element'] == 'TMAX'].set_index('Date')\n",
    "    df_min_2015 = df_yes_2015[df_yes_2015['Element'] == 'TMIN'].set_index('Date')\n",
    "    #df_yes_2015['TMAX'] = df_yes_2015['TMAX']\n",
    "    df_no_2015 = df[(df['Date'].dt.year != 2015) & (((df['Date'].dt.month == 2) & (df['Date'].dt.day == 29)) == False)]\n",
    "    df_no_2015['Date']=df_no_2015['Date'].apply(lambda x: x.replace(year=2015))\n",
    "    #df_no_2015.groupby('Month')\n",
    "    #df_no_2015 = df_no_2015.set_index(['Month'])\n",
    "    #df_no_2015.groupby('Month',axis=1).mean()\n",
    "    df_max_no_2015 = df_no_2015[df_no_2015['Element'] == 'TMAX']\n",
    "    df_min_no_2015 = df_no_2015[df_no_2015['Element'] == 'TMIN']\n",
    "    df_max_no_2015 = (df_max_no_2015.set_index('Date').groupby(level=0)['Data_Value']\n",
    "    .agg({'TMAX': np.max}))\n",
    "    df_min_no_2015 = (df_min_no_2015.set_index('Date').groupby(level=0)['Data_Value']\n",
    "    .agg({'TMIN': np.min}))\n",
    "    \n",
    "    df_max_2015 = (df_max_2015.groupby(level=0)\n",
    "    .agg({'Data_Value': np.max}))\n",
    "    df_min_2015 = (df_min_2015.groupby(level=0)\n",
    "    .agg({'Data_Value': np.min}))\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    observation_months = list()\n",
    "    plt.gca().set_color_cycle(['green'])\n",
    "    plt.plot(df_min_no_2015.index, df_min_no_2015['TMIN'], '-+',  df_max_no_2015.index, df_max_no_2015['TMAX'], '-x')\n",
    "    \n",
    "\n",
    "    #plt.gca().fill_between(range(len(df_min_no_2015['TMIN'])), df_min_no_2015['TMIN'], df_max_no_2015['TMAX'], facecolor='blue', alpha=0.6)\n",
    "    #plt.gca().fill_between(range(365), df_no_2015['TMIN'], df_no_2015['TMAX'], facecolor='blue', alpha=0.6)\n",
    "    plt.gca().set_color_cycle(['yellow','red'])\n",
    "    plt.plot(df_min_2015.index, df_min_2015['Data_Value'], 'o',  df_max_2015.index, df_max_2015['Data_Value'], 'x')\n",
    "    \n",
    "    plt.gca().fill_between(df_min_no_2015.index.values , df_min_no_2015['TMIN'].values, df_max_no_2015['TMAX'].values, facecolor='cyan', alpha=1, zorder=10)\n",
    "\n",
    "    # Axis\n",
    "    x = plt.gca().xaxis\n",
    "\n",
    "# rotate the tick labels for the x axis\n",
    "    for item in x.get_ticklabels():\n",
    "        item.set_rotation(45)\n",
    "    plt.xlabel('Month', fontsize=18)\n",
    "    plt.ylabel('Temperature', fontsize=18)\n",
    "    plt.title('Temperature in Leuven, Belgium', fontsize=18)\n",
    "    locator = mdates.MonthLocator()  # every month\n",
    "    fmt = mdates.DateFormatter('%b')\n",
    "    X = plt.gca().xaxis\n",
    "    X.set_major_locator(locator)\n",
    "    X.set_major_formatter(fmt)\n",
    "    # add a legend with legend entries (because we didn't have labels when we plotted the data series)\n",
    "    plt.legend(['TMIN 2005-2014', 'TMAX 2005-2014','TMIN 2015','TMAX 2015'])\n",
    "    return fig#df_no_2015#observation_dates\n",
    "plot_max_temp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
